{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: [Your name] and (your onyen)\n",
    "\n",
    "Names and Onyens of fellow students you discussed Homework4 problems and ideas:\n",
    "\n",
    "- Students: \n",
    "\n",
    "We encourage discussing ideas and brainstorming with your peers, but the final text, code, and comments in this homework assignment MUST be 100% written by you as mentioned in syllabus.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6: Modeling, Decision Trees, Linear Regression (50 points)\n",
    "\n",
    "Please complete this notebook by filling in the cells provided.\n",
    "\n",
    "!! Please submit a PDF of your notebook. You can make a PDF from JupyterHub by 1. File->Print or 2. Command+P (on Mac), then choose 'Save to PDF'. This saves the file on your laptop. All problems will be manually graded, so no need to submit ipynb or zip file. But you need to make sure all your code is visible and not cut off in the pdf. If we can't see your answer code for a coding problem, points may be deducted.\n",
    "\n",
    "!! Points will also be deducted if you do not include your name and Onyen in the Markdown cell above!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1. You need a loan?  Hmm, let me decide (25 points)\n",
    "Many of you have expressed interest in financial technology, so for this problem you will be using historic data from a bank about whether or not people were granted loans.  You'll be using this data to create a predictor for whether the bank would grant loans to future applicants.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 1.1 Data Preparation (4 points)**\n",
    "First, load the loan data into a table named `loan_data_raw`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data_raw = pd.read_csv('loan_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.1.1 (1 point)\n",
    "We don't need the `Loan_ID` column, so drop that column and store the resulting table in `loan_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.1.2 (1 point)\n",
    "Some of the values are missing from the table, so write the code to drop rows from `loan_data` that have any missing values, and store the result in `loan_data_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.1.3 (2 points)\n",
    "You'll be using functions from `scikit-learn`, which don't know how to handle text values like `Male` or `Female` or `Yes` or `No`, so you'll have to turn them into numbers. For the `Gender` and `Married` columns, use boolean indexing to do this by assigning 0 for `Male` and 1 for `Female` and 0 for `No` and 1 for `Yes` (just like we did in lecture demo).  Some of the code is already provided, you fill in the rest.  \n",
    "\n",
    "**WARNING:** running this cell twice will set `Gender` and `Married` to all zeroes!  (think about why this is so)  If you do this accidentally, you can always just run the cell above that drops values to re-create `loan_data_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.1.4 (0 points)\n",
    "Copy the code below that will do the same thing (a faster way) for the remaining columns.\n",
    "```Python\n",
    "loan_data_clean['Loan_Status'] = loan_data_clean.Loan_Status.replace({'N': 0, 'Y': 1})\n",
    "loan_data_clean['Property_Area'] = loan_data_clean.Property_Area.replace({'Rural':0, 'Urban':1, 'Semiurban':2})\n",
    "loan_data_clean['Education'] = loan_data_clean.Education.replace({'Graduate':0, 'Not Graduate':1})\n",
    "loan_data_clean['Dependents'] = loan_data_clean.Dependents.replace({'0':0, '1':1,'2':2,'3+':3})\n",
    "loan_data_clean = loan_data_clean.astype(float)\n",
    "loan_data_clean\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy code here and run it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 1.2 Train and Test, part 1 (12 points)**\n",
    "Next, you'll be creating your training set and your test set.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.2.1 (2 points)\n",
    "As we did in class and lab, create the training data from 80% of `loan_data_clean` by using random sampling.  The create the test set by dropping from `loan_data_clean` all the rows that are in the training set.  We set the random seed below to make the sampling reproducible so that everyone will be working with the same training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(420) # this makes the sampling reproducible, so everyone has same train and test\n",
    "# write your code here\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "# END SOLUTION\n",
    "print(train_loan.shape, test_loan.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.2.2 (2 points)\n",
    "You will be trying to predict `Loan_Status` from all the other data.  Create the approriate `X_train_loan`, `y_train_loan`, `X_test_loan`, and `y_test_loan` tables for the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.2.3 (2 points)\n",
    "Finally, use the `DecisionTreeClassifier` to create a decision tree to use for prediction.  Finish the code to print the scores of the classifier on the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "T = DecisionTreeClassifier(max_depth=3)\n",
    "T.fit(X_train_loan, y_train_loan)\n",
    "# write your code here\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "\n",
    "# END SOLUTION\n",
    "print('Score on train:', train_score)\n",
    "print('Score on test:', test_score)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (20, 20))\n",
    "p = plot_tree(T, filled = True, feature_names = X_train_loan.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.2.4 (2 points)\n",
    "Looking at the decision tree, which feature is the most important for predicting if a loan would be approved? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.2.5 (2 points)\n",
    "Next, we're going to gather some data for creating decision trees of different maximum tree depths.  Finish the code below to call the decision tree classifier with different maximum depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores=[]\n",
    "test_scores=[]\n",
    "r=range(1,13)\n",
    "for i in r:\n",
    "    # write your code here\n",
    "    # BEGIN SOLUTION\n",
    "\n",
    "    # END SOLUTION\n",
    "    T.fit(X_train_loan, y_train_loan)\n",
    "    train_scores.append(T.score(X_train_loan, y_train_loan))\n",
    "    test_scores.append(T.score(X_test_loan, y_test_loan))\n",
    "fig, ax = plt.subplots(1)\n",
    "sns.lineplot(x=r,y=train_scores,label='train')\n",
    "sns.lineplot(x=r,y=test_scores,label='test')\n",
    "ax.set_ylabel('Prediction score', fontsize=14)\n",
    "ax.set_xlabel('Max tree depth', fontsize=14)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.2.6 (2 points)\n",
    "Observe the generated plot.\n",
    "1. Does the accuracy improve for the **train** set as the maximum tree depth increases?\n",
    "2. Does the accuracy improve for the **test** set as the maximum tree depth increases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 1.3 Train and Test, part 2 (9 points)**\n",
    "You may have noticed that the `Credit_History` feature dominates the loan decision process (which makes sense!)  Using just this feature (max tree depth == 1), the prediction score is over 80%.  But what if you didn't have access to that feature?  How well could you predict what the bank would do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.3.1 (1 point)\n",
    "Finish the code below to drop the `Credit_History` column from your train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.3.2 (1 point)\n",
    "Finish the code below to create a new classifier fit to the new train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2 = DecisionTreeClassifier(max_depth=3)\n",
    "# write your code here\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "\n",
    "# END SOLUTION\n",
    "\n",
    "print('Score on train:', T2.score(X2_train_loan, y_train_loan))\n",
    "print('Score on test:', T2.score(X2_test_loan, y_test_loan))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize = (20, 20))\n",
    "p = plot_tree(T2, filled = True, feature_names = X2_train_loan.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.3.3 (1 point)\n",
    "How do the new scores for the train and test data compare to the previous scores that you printed?  Explain why you might have expected this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.3.4 (1 point)\n",
    "Once again, finish the code to gather prediction scores at different max tree depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores=[]\n",
    "test_scores=[]\n",
    "r=range(1,13)\n",
    "for i in r:\n",
    "    T = DecisionTreeClassifier(max_depth=i)\n",
    "    # write your code here\n",
    "    # BEGIN SOLUTION\n",
    "    \n",
    "    # END SOLUTION\n",
    "    train_scores.append(T.score(X2_train_loan, y_train_loan))\n",
    "    test_scores.append(T.score(X2_test_loan, y_test_loan))\n",
    "fig, ax = plt.subplots(1)\n",
    "sns.lineplot(x=r,y=train_scores,label='train')\n",
    "sns.lineplot(x=r,y=test_scores,label='test')\n",
    "ax.set_ylabel('Prediction score', fontsize=14)\n",
    "ax.set_xlabel('Max tree depth', fontsize=14)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probelm 1.3.5 (2 points)\n",
    "\n",
    "You should notice that increasing the tree depth dramatically improves the prediction score for the train set. This is because without `Credit_History`, there is no one primary feature correlated to the outcome, so we need more features to explain the loan decision data. At roughly what tree depth is the predictor able to predict as well for the train data as the previous predictor did using just `Credit_History`? (i.e. > 80%)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1.3.6 (3 points)\n",
    "You should see that for the test data, the predictor never gets near to the 80% mark.  No matter how deep the tree, the prediction score for the test data does not improve the same way as it did for the train data.  Why is this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2. Parkinsons progression detection (25 points)\n",
    "\n",
    "We will reproduce some of the qualitative results from \n",
    "the following paper, which I've downloaded for you in the same folder:\n",
    "\n",
    "    A. Tsanas, M. A. Little, P. E. McSharry and L. O. Ramig, \"Accurate Telemonitoring of Parkinson's Disease Progression by Noninvasive Speech Tests,\" in IEEE Transactions on Biomedical Engineering, vol. 57, no. 4, pp. 884-893, April 2010, doi: 10.1109/TBME.2009.2036000.\n",
    "\n",
    "The Parkinsons Telemonitoring dataset was downloaded from https://archive.ics.uci.edu/dataset/189/parkinsons+telemonitoring.\n",
    "\n",
    "**It is not necessary for you to read or understand the paper in order to complete this problem. You only need to look at the Tables and Figures in the paper that I point to.**\n",
    "\n",
    "For context, this dataset is composed of a range of biomedical voice measurements from 42 people with early-stage Parkinson's disease recruited to a six-month trial of a telemonitoring device for remote symptom progression monitoring. The recordings were automatically captured in the patient's homes.\n",
    "    \n",
    "Physical test observations are mapped to a metric specifically designed to follow disease progression, typically the unified Parkinson’s disease rating scale (UPDRS) that reflects the presence and severity of symptoms (but does not quantify their underlying causes). For untreated patients, the **total UPDRS spans the range 0–176**, with 0 representing healthy state and 176 representing total disabilities, and consists of three sections: 1) mentation, behavior, and mood; 2) activities of daily living; and 3) motor. The **motor UPDRS ranges from 0 to 108**, with 0 denoting symptom free and 108 denoting severe motor impairment, and encompasses tasks such as speech, facial expression, tremor, and rigidity. \n",
    "\n",
    "Columns in the table contain subject number, subject age, subject gender, time interval from baseline recruitment date, motor UPDRS, total UPDRS, and 16 biomedical voice measures. Each row corresponds to one of 5,875 voice recording from these individuals. **The main aim is to predict the motor and total UPDRS scores from the 16 voice measures.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinsons = pd.read_csv('parkinsons_updrs.csv')\n",
    "parkinsons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 2.1 (2 points) Concepts of machine learning**\n",
    "\n",
    "Given the data format and the description above,\n",
    "- Is this more of a **regression** problem or a **classification** problem? Pick one closest answer.\n",
    "- What do the **samples** correspond to, and how many are there?\n",
    "- What are the **target variables (labels, y)**, and how many are there?\n",
    "- What are the **predictor variables (features, X)**, and how many are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 2.2 (6 points) Exploring correlations**\n",
    "\n",
    "Open the paper pdf file and scroll down to page 887, Table 1. It looks scary, but all it's doing is calculating the **correlations** between each of the voice features with the UPDRS scores. We'll recreate this table step by step.\n",
    "\n",
    "#### Step 1 (1 point)\n",
    "\n",
    "Drop the columns `subject#`, `age`, `sex`, `test_time` and save the resulting table to a new variable `parkinsons_small`. Your new table should be of size (5875, 18)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "# write your code here\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "# END SOLUTION\n",
    "print(parkinsons_small.shape)\n",
    "parkinsons_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2 (0 point, it's just copy pasting)\n",
    "\n",
    "Copy and run the following code, which calculates the correlation between each pairs of columns in `parkinsons_small`. Your new table should be of size (18, 18).\n",
    "\n",
    "```Python\n",
    "corrs = parkinsons_small.corr(method='spearman')\n",
    "print(corrs.shape)\n",
    "corrs\n",
    "```\n",
    "\n",
    "How to read the table: The correlation between `Jitter(%)` and `total_UPDRS` is 0.129237.\n",
    "\n",
    "Out of scope for DATA110 but just in case you're curious: There are a few mathematical definitions of how to calculate correlation, and Pearson's and Spearman's are two of the most popular methods. The main difference is that Spearman's cares about the ranking of the values, and not the raw values. So it has fewer assumptions on the data than Pearson's and can handle outliers better. But the way the correlation values are interpreted are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2\n",
    "# copy code here and run it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3 (2 points)\n",
    "\n",
    "Since we're only interested in the correlations with the UPDRS scores, \n",
    "\n",
    "1. Keep only the columns `motor_UPDRS`,`total_UPDRS` and save the new table to `corrs_table1`.\n",
    "2. Within the table `corrs_table1`, drop the rows with index `motor_UPDRS`,`total_UPDRS` and save the new table to `corrs_table1` (overwrite it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "# write your code here\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "# END SOLUTION\n",
    "print(corrs_table1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4 (3 points) Interpretation\n",
    "\n",
    "Compare what you have with the numbers in Table 1, and check if they are **roughly** the same. \n",
    "\n",
    "**Note**: The numbers won't be exactly the same, because 5923 recordings are analyzed in the paper, but we only have access to 5875 of them. \n",
    "\n",
    "Question: What are your interpretations of these values? Do any of the biomedical voice variables seem highly correlated with the Parkinson's scores? Which variable do you think would be the most important in predicting UPDRS? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 2.3 (6 points) Prepare data for ML**\n",
    "\n",
    "Now comes the actual prediction! We will train and test a **linear regression** model to predict motor_UPDRS from the 16 voice variables. In other words, we are assuming that the motor_UPDRS scores are **approximately** equal to\n",
    "\n",
    "c1\\*Jitter(%) + c2\\*Jitter(Abs) + c3\\*Jitter:RAP + ... + c16\\*PPE\n",
    "\n",
    "for some set of coefficients (c1, c2, c3, ..., c16). And when we train or fit a linear regression model, we are looking for the best set of coefficients that describes the training dataset. When we test the model, we compare the model's predictions with the actual motor_UPDRS scores in the test dataset. If any of this sounds foreign to you, now would be a good time to review the past few lectures.\n",
    "\n",
    "#### Problem 2.3.1 (2 points)\n",
    "\n",
    "In an ideal world, we would train our model on the entire dataset, collect data from new patients, then test it on the new data. However, this is obviously not feasible in this case. In cases like this, most people randomly split the *existing* samples into train and test, and \"pretend\" like the samples in the test set are actually coming from future patients.\n",
    "\n",
    "We can split the data by patients or by recordings. The authors of this paper chose to split by recordings. \n",
    "\n",
    "**Fill in the blank** such that this sentence describes what the code does:\n",
    "\n",
    "    We will randomly put __1__% of the ___2____ into the __3___ set, and put the remaining __2_____ into the ____3___ set.\n",
    "\n",
    "- Options for 1: number between 0 and 100\n",
    "- Options for 2: rows or columns\n",
    "- Options for 3: train or test\n",
    "\n",
    "The corresponding code:\n",
    "\n",
    "```Python\n",
    "train = parkinsons_small.sample(frac=0.9)\n",
    "test = parkinsons_small.drop(index=train.index)\n",
    "```\n",
    "\n",
    "And then copy and run the code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy code here and run it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2.3.2 (4 points)\n",
    "\n",
    "Given your knowledge of what predictor variables and target variables are, create the following four variables: `X_train`, `y_train`, `X_test`, `y_test`. They are derived from tables `train` and `test`.\n",
    "\n",
    "Here's one way to check your answer:\n",
    "```Python\n",
    "print(X_train.shape, y_train.shape)\n",
    "    (5288, 16) (5288,)\n",
    "print(X_test.shape, y_test.shape)\n",
    "    (587, 16) (587,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "# BEGIN SOLUTION\n",
    "\n",
    "\n",
    "# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 2.4 (2 points) Train and test model**\n",
    "\n",
    "Copy the code, fill in the blanks (i.e., call with appropriate parameters), and run the code in the next cell.\n",
    "\n",
    "```Python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression(fit_intercept=False)\n",
    "lr.fit(..., ...)\n",
    "print(lr.score(..., ...))\n",
    "\n",
    "coefs = pd.DataFrame(lr.coef_, \n",
    "                     index=lr.feature_names_in_, \n",
    "                    columns=['Motor UPDRS LR coefficients'])\n",
    "coefs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the skeleton code here and complete it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 2.5 (4 points) Analyze model results**\n",
    "\n",
    "#### Problem 2.5.1 (2 points)\n",
    "\n",
    "Given the $R^2$ score that is printed out, do you think this linear regression model is a good predictive model of motor_UPDRS or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2.5.2 (2 points)\n",
    "Out of the 16 features, which one(s) are deemed the most *important* or *useful* at predicting motor_UPDRS according to the model? Comment on both the magnitude and direction (negative vs. positive) of the coefficient values and what that means in the context of the problem we're interested in. Are they the same variables you mentioned in Problem 4.2 (based on correlations)? You are welcome to compare your numbers with the reulsts in Table 3 (first column), but not required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answers here!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem 2.6 (5 points) Repeating the experiment multiple times**\n",
    "\n",
    "You might say - but Harlin, this is only based on a specific train/test split. What if it just so happened that this set of samples leads to this result? How can we trust our interpretations are generally true? \n",
    "\n",
    "You are absolutely right! That's why the authors of this paper repeated this 1000 times to create Table 3. \n",
    "\n",
    "Fill in the missing parts of the code below (you shouldn't have to write new code, just copy paste from earlier problems). \n",
    "\n",
    "```Python\n",
    "coefs = pd.DataFrame([], columns=lr.feature_names_in_)\n",
    "\n",
    "for i in range(1000):\n",
    "    train = parkinsons_small.sample(frac=0.9)\n",
    "    test = parkinsons_small.drop(train.index)\n",
    "\n",
    "    #####\n",
    "    # Add four lines of code here that creates X_train, y_train, X_test, y_test. \n",
    "    #####\n",
    "    \n",
    "    lr = LinearRegression(fit_intercept=False)\n",
    "    # fill in the parameters here\n",
    "    lr.fit(..., ...)\n",
    "\n",
    "    coefs.loc[len(coefs)] = lr.coef_\n",
    "\n",
    "coefs.mean()\n",
    "```\n",
    "\n",
    "Then tell us, **how did your analysis on the importance of each feature change?** If it didn't change, that's is also okay.\n",
    "\n",
    "\n",
    "**Note**: Again, you won't get the same numbers as Table 3 because we don't have access to the full dataset, and there is some randomness involved. But my coefficients except for Jitter (%) looks *qualitatively* similar (I get a 40-ish number for Jitter (%) instead of a -80-ish number, which is odd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the skeleton code here and complete it\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should give you pretty box plots once you're done with the previous question.\n",
    "sns.boxplot(coefs, orient='h')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here: How did your analysis of the importance of each feature change?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra credit (1 extra credit point)\n",
    "\n",
    "How many hours did you spend on each of HW1, HW2, HW3, HW4, HW5, and HW6? Your answer won't affect your grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
